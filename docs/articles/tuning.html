<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tuning spaceMap Model • spacemap</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">spacemap</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/basics.html">Basics</a>
    </li>
    <li>
      <a href="../articles/tuning.html">Model Tuning</a>
    </li>
    <li>
      <a href="../articles/ensemble.html">Ensemble Network</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">R Documentation</a>
</li>
<li>
  <a href="https://github.com/topherconley/spacemap/releases/tag/v0.45.0-beta">Installation</a>
</li>
<li>
  <a href="https://topherconley.github.io/neta-bcpls/">Network Toolkit</a>
</li>
<li>
  <a href="https://github.com/topherconley/spacemap/issues">Contact Us</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/topherconley/spacemap">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Tuning spaceMap Model</h1>
                        <h4 class="author">Christopher Conley, Pei Wang, Jie Peng</h4>
            
            <h4 class="date">2017-04-13</h4>
          </div>

    
    
<div class="contents">
<div id="tuning-strategy" class="section level2">
<h2 class="hasAnchor">
<a href="#tuning-strategy" class="anchor"></a>Tuning Strategy</h2>
<p>The three tuning parameters in Spacemap provides a rich framework for discovering conditional dependencies between variables in high dimensional biological assays; however, exploring a large tuning grid can be very computationally demanding. In this tutorial we illustrate a strategy for finding the neighborhood of good tuning parameters. The strategy finds suitiable neighborhoods of each tuning parameter by:</p>
<ol style="list-style-type: decimal">
<li>Cross validation of SPACE model on <span class="math inline">\(Y\)</span> input data across a one-dimensional grid of tuning penalty <span class="math inline">\(\lambda_1\)</span>, parameterized as <code>lam1</code>. Identify best performing neighborhood of <span class="math inline">\(\lambda_1\)</span>.</li>
<li>Cross validation of <code>spacemap</code> with input <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> across a three-dimensional grid of <span class="math inline">\(\lambda_1, \lambda_2, \lambda_3\)</span>. The neighborhood of <span class="math inline">\(\lambda_1\)</span> is specified from step 1. Explore a broad range of values for <span class="math inline">\(\lambda_2, \lambda_3\)</span>, which are parameterized as <code>lam2</code> and <code>lam3</code>.<br>
</li>
<li>Repeat step 2 if further refinement of the tuning penalties is needed.</li>
</ol>
</div>
<div id="tuning-example" class="section level2">
<h2 class="hasAnchor">
<a href="#tuning-example" class="anchor"></a>Tuning Example</h2>
<p>We will illustrate the details of this strategy with an example from a simulation. The simulation has a known true network topolog, which affords an evaluation of whether this tuning strategy leads to reasonably tuned parameter selection.</p>
<div id="simulation-details" class="section level3">
<h3 class="hasAnchor">
<a href="#simulation-details" class="anchor"></a>Simulation Details</h3>
<p>Load network simulation 1 which has topology that mimics a genetic regulatory network. The simulation was generated under a multivariate normal assumption with 171 response variables with 14 predictor variables (i.e. <span class="math inline">\(Y\)</span> = response, <span class="math inline">\(X\)</span> = predictors). There are 10 predictors that have no <span class="math inline">\(x-y\)</span> edges, 2 predictors with 13 <span class="math inline">\(x-y\)</span> edges and 2 predictors with 14 <span class="math inline">\(x-y\)</span>` edges. Among the response edges <span class="math inline">\(y-y\)</span>, there are 2 hub variables with degree 12 and 13, but the degree of the other response variables does not exceed 4. There are two disconnected components in the graph of size 94 and 81. The data has been standardized (mean-centered with unit variance) for all variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(spacemap)
<span class="kw">data</span>(sim1)</code></pre></div>
<p>Extract data objects and report dimensions and sample size.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat &lt;-<span class="st"> </span>sim1[<span class="kw">c</span>(<span class="st">"XY"</span>, <span class="st">"X"</span>, <span class="st">"Y"</span>, <span class="st">"Xindex"</span>, <span class="st">"Yindex"</span>)]
N &lt;-<span class="st"> </span><span class="kw">nrow</span>(dat$X)
P &lt;-<span class="st"> </span><span class="kw">ncol</span>(dat$X)
Q &lt;-<span class="st"> </span><span class="kw">ncol</span>(dat$Y)</code></pre></div>
<p>Extract the true partial correlation values, where non-zero partial correlations denote edges <span class="math inline">\(x-y\)</span> and <span class="math inline">\(y-y\)</span> edges.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trueParCor &lt;-<span class="st"> </span>sim1$trueParCor
<span class="kw">str</span>(trueParCor)</code></pre></div>
<pre><code>## List of 2
##  $ xy: num [1:14, 1:171] -1.00e-01 -1.42e-16 0.00 0.00 0.00 ...
##  $ yy: num [1:171, 1:171] 1.00 2.26e-18 2.51e-18 -1.46e-17 -1.65e-17 ...</code></pre>
<p>Tuning will be much faster if parallel computation is leveraged. Set up a parallel backend, in this case for a multicore machine. This code will use all available cores minus 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dopar &lt;-<span class="st"> </span><span class="ot">FALSE</span>
if (dopar) { 
  <span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(doParallel))
  <span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(parallel))
  ncores &lt;-<span class="st"> </span><span class="kw">detectCores</span>()  -<span class="st"> </span><span class="dv">1</span>
  cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(ncores)
  <span class="kw">registerDoParallel</span>(cl)
}</code></pre></div>
</div>
</div>
<div id="find-a-neighborhood-for-lam1" class="section level2">
<h2 class="hasAnchor">
<a href="#find-a-neighborhood-for-lam1" class="anchor"></a>Find a neighborhood for <code>lam1</code>
</h2>
<p>Tune the <code>lam1</code> parameter by fitting the <code>space.joint</code> function from the SPACE model to <span class="math inline">\(Y\)</span> over a one-dimensional tuning grid. In the current implementation, the tuning parameter scales with the sample size. To find the right tuning scale, use a result from Meinshausen and Buhlmann (2006) which applies when when all <span class="math inline">\(Y\)</span> have been standardized to have unit variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lam1start &lt;-<span class="st"> </span>function(n, q, alpha) { 
  <span class="kw">sqrt</span>(n) *<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> -<span class="st"> </span>(alpha/<span class="st"> </span>(<span class="dv">2</span>*q^<span class="dv">2</span>)))
}
lam0 &lt;-<span class="st"> </span><span class="kw">lam1start</span>(<span class="dt">n =</span> <span class="kw">floor</span>(N -<span class="st"> </span>N*.<span class="dv">10</span>), <span class="dt">q =</span> Q, <span class="dt">alpha =</span> <span class="fl">1e-5</span>)
lam0</code></pre></div>
<pre><code>## [1] 72.94889</code></pre>
<p>The value of <span class="math inline">\(\alpha\)</span> is meant to control the false discovery rate; in our experience with this result, <span class="math inline">\(\alpha\)</span> should be set very conservatively to obtain an initial value closer to the CV-selected <code>lam1</code>. In our case, we set <code>alpha = 1e-5</code>. Take the initial grid search to range from [80% of <code>lam0</code>, 120% of <code>lam0</code>].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#neighborhood parameter about lam0. </span>
eps1 &lt;-<span class="st"> </span><span class="fl">0.8</span>
<span class="co">#initial grid size. </span>
ngrid &lt;-<span class="st"> </span><span class="dv">30</span>
<span class="co">#grid</span>
tsp &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">lam1 =</span> <span class="kw">seq</span>(lam0*eps1, lam0*(<span class="dv">1</span> +<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>eps1)), <span class="dt">length =</span> ngrid))
<span class="kw">summary</span>(tsp)</code></pre></div>
<pre><code>##       lam1      
##  Min.   :58.36  
##  1st Qu.:65.65  
##  Median :72.95  
##  Mean   :72.95  
##  3rd Qu.:80.24  
##  Max.   :87.54</code></pre>
<p>In preparation of 10-K cross validation, we encourage the user to determine the split of the data since the data may have some special underlying population structure that needs to be balanced across the hold-out sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#for generating cross-validation folds</span>
<span class="kw">library</span>(caret)
<span class="co">#sample size</span>
N &lt;-<span class="st"> </span><span class="kw">nrow</span>(dat$X)
<span class="co">#number of folds</span>
K &lt;-<span class="st"> </span>10L
<span class="kw">set.seed</span>(265616L)
<span class="co">#no special population structure, but create randomized dummy structure of A and B</span>
testSets &lt;-<span class="st"> </span><span class="kw">createFolds</span>(<span class="dt">y =</span> <span class="kw">sample</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>), <span class="dt">size =</span> N, <span class="dt">replace =</span> <span class="ot">TRUE</span>), <span class="dt">k =</span> K)
trainSets &lt;-<span class="st"> </span><span class="kw">lapply</span>(testSets, function(s) <span class="kw">setdiff</span>(<span class="kw">seq_len</span>(N), s))
nsplits &lt;-<span class="st"> </span><span class="kw">sapply</span>(testSets, length)</code></pre></div>
<p>Conduct the cross-validation of the SPACE model through the <code>cvVote</code> function. It takes as input the data <span class="math inline">\(Y\)</span>, how <span class="math inline">\(Y\)</span> should be split for testing and training, an indication to to learn <span class="math inline">\(y-y\)</span> edges through the SPACE model, and finally a grid of tuning penalties.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvspace &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cvVote.html">cvVote</a></span>(<span class="dt">Y =</span> dat$Y, 
                  <span class="dt">trainIds =</span> trainSets, <span class="dt">testIds =</span> testSets, 
                  <span class="dt">method =</span> <span class="st">"space"</span>, <span class="dt">tuneGrid =</span> tsp) </code></pre></div>
<p>The <code>tuneVis</code> function plots several diagonostic metrics for tuning the models. Below the plot on the left shows the log(CV score) curve aross <code>lam1</code>, where the vertical line denotes the minimizer. The CV score curve has an approximately convex shape with a little bit variability at the valley. To the right the average number of y–y edges across CV training splits is shown to decrease with increasing <code>lam1</code>. The intersecting lines indicate the optimal lambda produces a CV.vote SPACE model of 162 y–y edges, which is about 30 edges lower than the average no. of edges due to the model stabilizing influence of the CV.vote procedure.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvVis &lt;-<span class="st"> </span><span class="kw"><a href="../reference/tuneVis.html">tuneVis</a></span>(<span class="dt">cvOut =</span> cvspace, 
                 <span class="dt">testSetLen =</span> nsplits, 
                 <span class="dt">tuneParam1 =</span> tsp$lam1,
                 <span class="dt">tuneParam1Name =</span> <span class="st">"lam1"</span>)
<span class="kw">library</span>(gridExtra)
<span class="kw">grid.arrange</span>(cvVis[[<span class="dv">1</span>]] +<span class="st"> </span>
<span class="st">               </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> cvspace$minTune$lam1),
             cvVis[[<span class="dv">3</span>]] +<span class="st"> </span>
<span class="st">               </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">nonZeroUpper</span>(cvspace$cvVote$yy,<span class="dv">0</span>)) +<span class="st"> </span>
<span class="st">                 </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span>  cvspace$minTune$lam1)
             , <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="tuning_files/figure-html/unnamed-chunk-10-1.png" width="672"></p>
<p>Since the true network is known, we can evaluate the learned SPACE network against the truth.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">spacePerf &lt;-<span class="st"> </span><span class="kw">cvPerf</span>(<span class="dt">cvOut =</span> cvspace, <span class="dt">trueParCor =</span> sim1$trueParCor, <span class="dt">method =</span> <span class="st">"space"</span>)[<span class="dv">1</span>:<span class="dv">3</span>]
spacePerf</code></pre></div>
<pre><code>##     power       fdr       mcc 
## 0.7820513 0.2469136 0.7648620</code></pre>
<p>The “mcc” refers to an average of the power and FDR. The power is reasonable, but the FDR is a little high. Let’s see the effect of conditioning on <span class="math inline">\(x\)</span> variables through the spaceMap model.</p>
</div>
<div id="find-a-neighborhood-for-lam2-and-lam3" class="section level2">
<h2 class="hasAnchor">
<a href="#find-a-neighborhood-for-lam2-and-lam3" class="anchor"></a>Find a neighborhood for <code>lam2</code> and <code>lam3</code>
</h2>
<p>Now shifting our attention to tuning all three tuning parameters, we can make use of the information from step 1 to reduce the grid search time. Input a neighborhood of <span class="math inline">\(65 \leq \lambda_1 \leq 75\)</span> into the 3-D grid search since we know that produces a reasonable output for the <span class="math inline">\(y--y\)</span> portion of the network. Choosing an initial neighborhood for <span class="math inline">\(\lambda_2, \lambda_3\)</span> is guided by practical considerations such as how many <span class="math inline">\(x-y\)</span> edges one might expect to see at maximum. In our case, we know there are only 14 <span class="math inline">\(x\)</span> variables and so we do not expect there to be more than say, 200 <span class="math inline">\(x-y\)</span> edges, but no less than 50 <span class="math inline">\(x-y\)</span> edges in a sparse network. Since we anticipate there existing a few hubs in the network, fix <span class="math inline">\(\lambda_3=15\)</span>. Now we can quickly obtain an approximate lower bound for <span class="math inline">\(\lambda_2\)</span> by applying the <code>initFit</code> function, which does not do any cross-validation, but simply fits <code>spacemap</code> across the defined tuning grid once.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tmap1 &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">lam1 =</span> cvspace$minTune[[<span class="dv">1</span>]], 
                     <span class="dt">lam2 =</span> <span class="kw">seq</span>(<span class="dv">15</span>, <span class="dv">60</span>, <span class="dt">by =</span> <span class="dv">5</span>), 
                     <span class="dt">lam3 =</span> <span class="dv">15</span>)
ntmap1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/initFit.html">initFit</a></span>(<span class="dt">Y =</span> sim1$Y, <span class="dt">X =</span> sim1$X, <span class="dt">method =</span> <span class="st">"spacemap"</span>, <span class="dt">tuneGrid =</span> tmap1)
<span class="kw">library</span>(ggplot2)
<span class="kw">qplot</span>(<span class="dt">x =</span> tmap1$lam2, <span class="dt">y =</span> ntmap1$nxy,
      <span class="dt">ylab =</span> <span class="st">"No. of X-&gt;Y edges"</span>, <span class="dt">xlab =</span> <span class="st">"lam2"</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="tuning_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<p>It is evident that restricting our attention to <code>20&lt; lam2&lt; 35</code> is the best course of action to limit the number of <span class="math inline">\(x-y\)</span> edges to the range we are targeting. Now that we have reasonable ranges for <code>lam1,lam2</code>, we also need to define a range for <code>lam3</code>, which is helpful for encouraging <span class="math inline">\(x\)</span> hub selection. We could use the <code>initFit</code> function to guide this process, but we will rely on what we expect to see—hubs are likely to exist in the network—such that the lower bound for <code>lam3</code> should be sufficiently far from 0. Now define the 3-D tuning grid:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tmap2 &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">lam1 =</span> <span class="kw">seq</span>(<span class="dv">65</span>, <span class="dv">75</span>, <span class="dt">length =</span> <span class="dv">5</span>), 
                    <span class="dt">lam2 =</span> <span class="kw">seq</span>(<span class="dv">21</span>, <span class="dv">35</span>, <span class="dt">length =</span> <span class="dv">5</span>), 
                    <span class="dt">lam3 =</span> <span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dt">length =</span> <span class="dv">5</span>))</code></pre></div>
<p>Apply cross validation with <code>spacemap</code> to learn the best network in the tuning grid. This will take about 4 minutes on a single processor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvsmap &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cvVote.html">cvVote</a></span>(<span class="dt">Y =</span> dat$Y, <span class="dt">X =</span> dat$X, 
                 <span class="dt">trainIds =</span> trainSets, <span class="dt">testIds =</span> testSets, 
                 <span class="dt">method =</span> <span class="st">"spacemap"</span>, <span class="dt">tuneGrid =</span> tmap2)</code></pre></div>
<p>The CV.vote spaceMap network is encoded into adjacency matrices <code>cvsmap$cvVote[c("xy", "yy")]</code>. The best penalties from the tuning grid are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvsmap$minTune</code></pre></div>
<pre><code>## $lam1
## [1] 70
## 
## $lam2
## [1] 28
## 
## $lam3
## [1] 17.5</code></pre>
<p>Next we diagnose the suitability of the tuning grid based on the output through <code>tuneVis</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvVis1 &lt;-<span class="st"> </span>spacemap::<span class="kw"><a href="../reference/tuneVis.html">tuneVis</a></span>(<span class="dt">cvOut =</span> cvsmap, <span class="dt">testSetLen =</span> nsplits, 
                            <span class="dt">tuneParam1 =</span> tmap2$lam1, <span class="dt">tuneParam1Name =</span> <span class="st">"lam1"</span>)
cvVis2 &lt;-<span class="st"> </span>spacemap::<span class="kw"><a href="../reference/tuneVis.html">tuneVis</a></span>(<span class="dt">cvOut =</span> cvsmap, <span class="dt">testSetLen =</span> nsplits, 
                            <span class="dt">tuneParam1 =</span> tmap2$lam2, <span class="dt">tuneParam1Name =</span> <span class="st">"lam2"</span>)
cvVis3 &lt;-<span class="st"> </span>spacemap::<span class="kw"><a href="../reference/tuneVis.html">tuneVis</a></span>(<span class="dt">cvOut =</span> cvsmap, <span class="dt">testSetLen =</span> nsplits, 
                            <span class="dt">tuneParam1 =</span> tmap2$lam3, <span class="dt">tuneParam1Name =</span> <span class="st">"lam3"</span>)</code></pre></div>
<p>Visualizing the CV scores across the 3-D grid shows the selected tuning penalties are away from their respective boundaries, which suggests the grid is suitable. If the selected penalty was on or near the boundary, it may suggest to increase (decrease) the upper (lower) bound of the penalty in the grid.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra)
<span class="kw">grid.arrange</span>(cvVis1[[<span class="dv">1</span>]], cvVis2[[<span class="dv">1</span>]],cvVis3[[<span class="dv">1</span>]], <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="tuning_files/figure-html/unnamed-chunk-17-1.png" width="672"></p>
<p>This whole tuning process took 5.32 minutes. The network learning performance of <code>spacemap</code> is listed below</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smapPerf &lt;-<span class="st"> </span><span class="kw">cvPerf</span>(<span class="dt">cvOut =</span> cvsmap, <span class="dt">trueParCor =</span> sim1$trueParCor, <span class="dt">method =</span> <span class="st">"spacemap"</span>)[<span class="dv">1</span>:<span class="dv">8</span>]
smapPerf</code></pre></div>
<pre><code>##      power        fdr        mcc    powerXY      fdrXY    powerYY 
## 0.76666667 0.07471264 0.84049251 0.87037037 0.07843137 0.73076923 
##      fdrYY      mccYY 
## 0.07317073 0.82133452</code></pre>
<p>The spaceMap model dramatically lowers the <span class="math inline">\(y-y\)</span> FDR when compared with SPACE in this example. The FDR is lowered from over 25% to below 8%, while experiencing a small drop in <span class="math inline">\(y-y\)</span> power. This benefit is beleived to be because spaceMap learns the <span class="math inline">\(x-y\)</span> edges that encode predictor variable perturbations to the response varialbes. With a relatively high <span class="math inline">\(x-y\)</span> power and limted overall FDR, spaceMap shows its added-value.</p>
<div id="refinement-of-grid" class="section level3">
<h3 class="hasAnchor">
<a href="#refinement-of-grid" class="anchor"></a>Refinement of Grid</h3>
<p>If time allows, further refinement of the tuning grid could be explored by narrowing the neighborhood about the previously optimal tuning set. However, note that refining the grid may lead to a better CV score, but worse performance due to over fitting.</p>
</div>
</div>
<div id="further-reading" class="section level2">
<h2 class="hasAnchor">
<a href="#further-reading" class="anchor"></a>Further Reading</h2>
<p>Completion of this vignette ought to have taught how to tune penalty parameters to near optimal settings for the <code>spacemap</code> model. We recommend looking at the <a href="https://topherconley.github.io/spacemap/articles/ensemble.html">next vignette</a> which illustrates how to have more precise control of the FDR through an ensembled network.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#tuning-strategy">Tuning Strategy</a></li>
      <li><a href="#tuning-example">Tuning Example</a></li>
      <li><a href="#find-a-neighborhood-for-lam1">Find a neighborhood for <code>lam1</code></a></li>
      <li><a href="#find-a-neighborhood-for-lam2-and-lam3">Find a neighborhood for <code>lam2</code> and <code>lam3</code></a></li>
      <li><a href="#further-reading">Further Reading</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="https://github.com/topherconley/">Christopher Conley</a>, <a href="http://www.stat.ucdavis.edu/~jie/">Jie Peng</a>, <a href="http://research.mssm.edu/wanglab/index.htm">Pei Wang</a>, UC Davis.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
